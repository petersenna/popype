[com]
name: 2015-10-28
author: Peter's Amazing Bot
email: peter.senna@gmail.com

[git_in]
# cloudspatch will checkout this git repository and run spatch in it.
# config_url points to a git configuration file. The example file
# includes the Linux kernel trees: linux, linux-next, linux-stable,
# and linux-staging (at least when I wrote this). If you want to
# use cloudspatch in a completely different project, consider
# creating your own version of the container coccinelle-linux-git
config_url: https://raw.githubusercontent.com/petersenna/docker/master/coccinelle-linux-git/config

# You can use anything that git checkout accept. You can specify one or
# more 'checkouts' using a comma as separator. Each 'checkout' will be
# processed independently with it's own output directory inside git_out.
# If you want to get all major Linux kernel versions, try this:
# $ git tag |egrep "^v2\.6\.[0-9]*$|^v[34]\.[0-9]*$"|sort -V|awk '{printf("%s, ", $0)}'
#
checkout: v2.6.11, v2.6.12, v2.6.13, v2.6.14, v2.6.15, v2.6.16, v2.6.17, v2.6.18, v2.6.19, v2.6.20, v2.6.21, v2.6.22, v2.6.23, v2.6.24, v2.6.25, v2.6.26, v2.6.27, v2.6.28, v2.6.29, v2.6.30, v2.6.31, v2.6.32, v2.6.33, v2.6.34, v2.6.35, v2.6.36, v2.6.37, v2.6.38, v2.6.39, v3.0, v3.1, v3.10, v3.11, v3.12, v3.13, v3.14, v3.15, v3.16, v3.17, v3.18, v3.19, v3.2, v3.3, v3.4, v3.5, v3.6, v3.7, v3.8, v3.9, v4.0, v4.1, v4.2

# However if you want to analyze commits, you can use ranges instead of fixed
# points. The pipeline will be applied to each point of the range. You can use
# from-to notation, but also specify single points.
# range: v2.6.12-v2.6.13, v2.6.18

[git_out]
# cloudspatch will save the results in this git repository, so you need
# write access, and cloudspatch only knows ssh authentication. The url
# should be something like git@github.com:petersenna/fake.git
repo_url: git@github.com:petersenna/fake.git

# cloudspatch will push the results to this branch. Using ${com:name}
# works very well for me
branch: ${com:name}

# Compress stderr and stdout before committing to git, valid
# values: gz, no
compress: gz

# Paste your private key here keeping in mind that the config parser
# expect at least one leading space for each line of your private
# key. For github I use deploy keys instead of using my default ssh
# key.
key: -----BEGIN RSA PRIVATE KEY-----
 MIIEowIBAAKCAQEAxKdmiz9zuFyJCoq9vSbg0juaJpMh9cbfxP0QzSSlld2qOBlv
 b4f7tHHgMtM/PwuBtlBJMIUM1Xbvk0dor7p8xDp/am5wj8BSaFRIqtZ/f1wjVJiL
 OnYPaUNCaTFGpt0Pdhali69o+FL1EuomfMQprBMS4tGaojDOgwM5V94bBUw6a6NU
 D+ZqQRjdBlnASrCCw+e3yZqDMhSU676SlAEHdQUi7g1iKF0LAz6CQVAfgYfT00vA
 vPIa7NWlUiTLQtMgL1lOfs+sr5qjjzYvrfiTKYew83Lk+in4lkvB/YdTafldUSfk
 96bdNAglNzIaffgSQJ+pHS2xl0RqEOMmbNBq6wIDAQABAoIBAGHBXUYnGp0w0qa8
 5Sjb5LJdEnnOdfk5DQ9dRTbU2sMu12jfq/djP4opeWuKe0wZqjc4nclSulh6sQkj
 XDTOnSrmcWQ01ht/XPejviO+UM68vItW8Q70lSCcYKzt49Ma3I61H0HaxnF6u3zV
 jKBE2vpA2QiLbTTm0iFqPt0g+YmdxPxxZqZfbvw/Id+PZMGgN/b4Tb/+e8LcvMi4
 XVwPI9GF1XtopRQu1p8TzvQ9JtV3sEzjlSL89TZASluSMX+63VYYwb3ktfBD9rtt
 RJOLyz6RUHI+X7BBY56Ur/oPlVl3klUyRNJWy86jRlL9I/0SYuv7VAxytiTqDlqy
 X8nPNDECgYEA9iz9oKHa0JDNbfI2pRtuw0aIhUDGlwJb19Qn4mPHhyo3nKuGSMuh
 OJl7fapIVOtTo3krFeRpJbEGIC6FUZL7d4+fc9EmznZ4ty8w+g9wnBDPr37IVOgm
 Sn9G1BGXWgFuCP4qJLgWkK6k5uPO/P2rDZgC04WrCtAtKfNOl6mFKh8CgYEAzIB6
 pVWTHB6K2PfutMUyXXmA6yZFKMLyRzWxEzJXpUhioZSYqnZ2LW0HAXJFA1Esrar8
 7b6yal9FJod2ktVSkO6izMe6qPghofLDB2BCytZMS4uG2zRIZFWZNOfOuTsuJmlN
 qtaRNZR3dmod7Nel7KQ50o91LZf04pE2vonX/bUCgYBtG93B71rja/qRC3Sq0zDR
 fhaOMPqT/ailTVPsJFtQDicd2mwnIZGwW15/gRSUBsVIRDETf+wWl5Jmexf94s5v
 3IlItN+lTJ8OWe00N9mqYk0atG+oKkimZikHX1CcxNt3Qud85Najg7R03W1ldiz1
 VnWSOMFphoEuAbfIworR8wKBgAJj5gsUqvmDKeBLVZDrVSFekDEva1OEo8xNRlqR
 FhEqfWyiDf7AD7WMNq6/pSrawgjtnLMyrWcs4eQHZU1mDOcAwwpds0LSU6JO8hSd
 /Wndg1rGsLbTL51smrPRmcr0dB+iz3OVunDD4XmS1/Kyuo+/g6WAY8A6rHQRenBT
 sCCZAoGBAKHl8dUDxz36rprTcztF4m8lLYZMBqK0hIveqEEirha8NpiSurxgoskV
 oL6JcMQuDGiiDm73Jqm+yXLS8xCfwqMxqepYDpx3lpUko7rBVeLx2bSBkFdoDq09
 /ayTMajBqpx8yVvXn7PDd233MoRwqceOVh8hZcTggkNBZs3Rln+M
 -----END RSA PRIVATE KEY-----
 
[script]
# Specify an url for downloading the scripts
# script_files_baseurl:
# You can specify names for script_files separated by comma:
script_files: log_f_names_from_if.cocci, log_f_args_count.cocci, log_f_calls.cocci, count_calls.py, filter_by_arg_count.py

# OR specify multiple script_file with arguments for each script
# script_file: log_f_names_from_if.cocci --timeout 120
# script_file: log_f_args_count.cocci --timeout 120
# script_file: log_f_calls.cocci --timeout 120
# script_file: count_calls.py --parallel
# script_file: filter_by_arg_count.py --parallel

[interpreter]
# Specify how to handle the script files. There are some special variables:
#    #SCRIPT#: Path to the script file
#    #CORES#: Number of coreas provided by nproc
#    #PIPEIDX#: Index on the pipe starting from 0
cocci: spatch #SCRIPT# -j #CORES# -D pipeidx=#PIPEIDX# -D pipestdout=#PIPESTDOUT# -D pipestderr=#PIPESTDERR# -dir . --timeout 120
#py: python3 -u

[pipeline]
# This is not like a pipe from Bash. Instead of doing stdout to stdin magic
# using real, and in memory pipes, stdout and stderr are saved to disk, and
# then full path to these files are passed around. Scripts and .cocci files can
# access the file /tmp/pipeline_conf, and parse it using configparser from
# Python. The contents of this configuration file and the following information
# are available trough the /tmp/pipeline_conf file:
#
#   pipeout:  path to file containing stdout of previous stage
#   pipeerr:  path to file containing stderr of previous stage
#   pipedirs: pipe separated list of full path to directories which contains
#             stdout and stderr of pipe stages
#   pipeline: the pipeline defined in this file
#   pipeidx:  number starting from 1 telling the current position on the
#             pipeline
pipeline: log_f_names_from_if.cocci | log_f_args_count.cocci | filter_by_arg_count.py | log_f_calls.cocci | count_calls.py
